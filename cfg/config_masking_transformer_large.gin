# general training parameters
train.wandb_params = {
    "project": "mtg-ssl",
    "name": "mask_transformer_large",
    "offline": True,
    # NOTE: path to logs in the BSC cluster. Change it for local experiments
    "save_dir": "/gpfs/projects/upf97/logs/",
    "entity": "mtg-upf",
    "group": "masking_transformer",
}

# modules to use
build_module.representation = @nets.melspectrogram.MelSpectrogram
build_module.module = @modules.maskingmodel.MaskingModel
build_module.net = @nets.transformer.Transformer

# Choose the devalopment dataloader
build_dev_datamodule.datamodule = @discotube

# Lighting trainer parameters
train.params = {
    "accelerator": "gpu",
    "devices": 4,
    "num_nodes": 2,
    "max_steps": 400000,
    "log_every_n_steps": 50,
    "precision": "bf16-mixed",
    "strategy": "ddp_find_unused_parameters_true",
    "num_sanity_val_steps": 0
}

# Dataloader
AudioDataset.num_frames = 480000 # 30s
AudioDataset.orig_freq = 16000
AudioDataset.new_freq = 16000
AudioDataset.mono = True
AudioDataset.half_precision = True
AudioDataModule.num_workers = 20

# Discogs datamodule parameters
DiscotubeAudioDataModule.batch_size = 32
DiscotubeAudioDataModule.data_dir = "/gpfs/scratch/upf97/mmap/"
DiscotubeAudioDataModule.filelist_train = "/gpfs/projects/upf97/data/train_mmap.txt"
DiscotubeAudioDataModule.filelist_val = "/gpfs/projects/upf97/data/test_mmap.txt"

# CosineAnnealing scheduler
CosineAnnealingCallback.warmup_steps = 30000
CosineAnnealingCallback.eta_min = 1e-7

# MelSpectrogram parameters
nets.melspectrogram.MelSpectrogram.sr = 16000
nets.melspectrogram.MelSpectrogram.win_len = 512
nets.melspectrogram.MelSpectrogram.hop_len = 256
nets.melspectrogram.MelSpectrogram.power = 2
nets.melspectrogram.MelSpectrogram.n_mel = 96
nets.melspectrogram.MelSpectrogram.norm = "slaney"
nets.melspectrogram.MelSpectrogram.mel_scale = "slaney"
nets.melspectrogram.MelSpectrogram.norm_std = 1.268292820667291
nets.melspectrogram.MelSpectrogram.norm_mean = 2.06755686098554

# data augmentation
nets.melspectrogram.MelSpectrogram.stretch_factor = 1
nets.melspectrogram.MelSpectrogram.freq_mask_param = 0
nets.melspectrogram.MelSpectrogram.time_mask_param = 0

# MaskingModel parameters
modules.maskingmodel.MaskingModel.num_codebooks = 4
modules.maskingmodel.MaskingModel.lr = 1e-4
modules.maskingmodel.MaskingModel.weight_decay = 1e-2
modules.maskingmodel.MaskingModel.codebook_size = 8192
modules.maskingmodel.MaskingModel.codebook_dim = 16
modules.maskingmodel.MaskingModel.mask_seconds = 0.4
modules.maskingmodel.MaskingModel.mask_prob = 0.6
modules.maskingmodel.MaskingModel.seed = 0
modules.maskingmodel.MaskingModel.plot_tokens = False
modules.maskingmodel.MaskingModel.diff_input = False

# Transformer parameters
nets.transformer.Transformer.patch_size = (96, 4)
nets.transformer.Transformer.in_chans = 1
nets.transformer.Transformer.embed_dim = 1280
nets.transformer.Transformer.head_dims = 1280
nets.transformer.Transformer.depth = 32
nets.transformer.Transformer.num_heads = 16
nets.transformer.Transformer.mlp_ratio=4.0
nets.transformer.Transformer.dropout=0.2
nets.transformer.Transformer.input_dropout=0.0
nets.transformer.Transformer.do_vit_tokenization = False
nets.transformer.Transformer.do_deepnorm = True
nets.transformer.Transformer.alpha_deepnorm = 2.6321480259049848
nets.transformer.Transformer.beta_deepnorm = 0.022386873579657126
nets.transfoemer.Transformer.num_patches = None
