# modules to use
build_module.representation = @nets.melspectrogram.MelSpectrogram
build_module.module = @modules.maskingmodel.MaskingModel
build_module.net = @nets.transformer.Transformer

# MelSpectrogram parameters
nets.melspectrogram.MelSpectrogram.sr = 16000
nets.melspectrogram.MelSpectrogram.win_len = 512
nets.melspectrogram.MelSpectrogram.hop_len = 256
nets.melspectrogram.MelSpectrogram.power = 2
nets.melspectrogram.MelSpectrogram.n_mel = 96
nets.melspectrogram.MelSpectrogram.norm = "slaney"
nets.melspectrogram.MelSpectrogram.mel_scale = "slaney"
nets.melspectrogram.MelSpectrogram.norm_std = 1.268292820667291
nets.melspectrogram.MelSpectrogram.norm_mean = 2.06755686098554

# MaskingModel parameters
modules.maskingmodel.MaskingModel.num_codebooks = 1
modules.maskingmodel.MaskingModel.lr = 1e-4
modules.maskingmodel.MaskingModel.codebook_size = 8192
modules.maskingmodel.MaskingModel.codebook_dim = 16
modules.maskingmodel.MaskingModel.mask_seconds = 0.4
modules.maskingmodel.MaskingModel.mask_prob = 0.6
modules.maskingmodel.MaskingModel.seed = 42
modules.maskingmodel.MaskingModel.plot_tokens = False

# Transformer parameters
nets.transformer.Transformer.patch_size = (96, 4)
nets.transformer.Transformer.in_chans = 1
nets.transformer.Transformer.embed_dim = 768
nets.transformer.Transformer.head_dims = 768
nets.transformer.Transformer.depth = 12
nets.transformer.Transformer.num_heads = 12
nets.transformer.Transformer.mlp_ratio=4.0
nets.transformer.Transformer.dropout=0.0
nets.transformer.Transformer.do_vit_tokenization = False
